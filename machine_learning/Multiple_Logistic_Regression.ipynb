{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a27702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  1.0\n",
      "[[4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sumed\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Question 1: The \"Data Leakage\" Trap\n",
    "# One of the most common mistakes in machine learning is Data Leakage—accidentally using information from the test set to scale or transform the training set.\n",
    "\n",
    "# The Rule: You must fit your scaler/encoder only on the training data, then transform both sets.\n",
    "\n",
    "# Dataset:\n",
    "\n",
    "# Python\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# data1 = {\n",
    "#     'Age': [22, 25, 47, 52, 46, 56, 55, 60, 62, 63, 18, 20, 21, 23, 24, 80, 85, 90, 88, 82],\n",
    "#     'Salary': [20000, 22000, 100000, 120000, 110000, 130000, 125000, 140000, 145000, 150000, 15000, 18000, 19000, 21000, 23000, 50000, 55000, 60000, 58000, 52000],\n",
    "#     'Purchased_VIP': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# }\n",
    "# df1 = pd.DataFrame(data1)\n",
    "# Your Tasks:\n",
    "\n",
    "# Split: Split X (Age, Salary) and y (Purchased_VIP) into training and testing sets (80/20 split, random_state=42).\n",
    "\n",
    "# Scale Correctly:\n",
    "\n",
    "# Import StandardScaler from sklearn.preprocessing.\n",
    "\n",
    "# Fit the scaler on X_train ONLY.\n",
    "\n",
    "# Transform X_train to create X_train_scaled.\n",
    "\n",
    "# Transform X_test to create X_test_scaled.\n",
    "\n",
    "# Train & Evaluate: Train a LogisticRegression model on the scaled training data. Calculate the accuracy on the scaled test data.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data1 = {\n",
    "    'Age': [22, 25, 47, 52, 46, 56, 55, 60, 62, 63, 18, 20, 21, 23, 24, 80, 85, 90, 88, 82],\n",
    "    'Salary': [20000, 22000, 100000, 120000, 110000, 130000, 125000, 140000, 145000, 150000, 15000, 18000, 19000, 21000, 23000, 50000, 55000, 60000, 58000, 52000],\n",
    "    'Purchased_VIP': [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "}\n",
    "df = pd.DataFrame(data1)\n",
    "\n",
    "x = df[['Age','Salary']]\n",
    "y = df['Purchased_VIP']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test,y_pred))\n",
    "\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(confusion_matrix)\n",
    "# cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1])\n",
    "# cm_display.plot()\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e484803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Question 2: Taming XGBoost (Hyperparameters)\n",
    "# XGBoost is powerful, but it can easily overfit if you let it grow too wild. Let's compare a \"default\" model vs. a \"constrained\" model.\n",
    "\n",
    "# Dataset:\n",
    "\n",
    "# Python\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# np.random.seed(99)\n",
    "# data2 = {\n",
    "#     'Feature_1': np.random.rand(200),\n",
    "#     'Feature_2': np.random.rand(200),\n",
    "#     'Feature_3': np.random.rand(200) * 100,\n",
    "#     'Target': np.random.randint(0, 2, 200)\n",
    "# }\n",
    "# df2 = pd.DataFrame(data2)\n",
    "# Your Tasks:\n",
    "\n",
    "# Split: Perform an 80/20 split (random_state=42).\n",
    "\n",
    "# Model 1 (Aggressive): Train an XGBClassifier with n_estimators=500 and max_depth=10 (this is very deep and detailed for such small data). Fit it on the training set.\n",
    "\n",
    "# Model 2 (Conservative): Train a second XGBClassifier with n_estimators=50 and max_depth=2.\n",
    "\n",
    "# Compare: Calculate and print the Training Accuracy and Testing Accuracy for both models.\n",
    "\n",
    "# Analyze: Which model has a bigger gap between Train and Test accuracy? Which one is overfitting more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.672279</td>\n",
       "      <td>0.327896</td>\n",
       "      <td>99.396040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.488078</td>\n",
       "      <td>0.568843</td>\n",
       "      <td>48.209367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.825495</td>\n",
       "      <td>0.781970</td>\n",
       "      <td>79.505741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031446</td>\n",
       "      <td>0.721964</td>\n",
       "      <td>83.108399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.808050</td>\n",
       "      <td>0.678653</td>\n",
       "      <td>51.774638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.836318</td>\n",
       "      <td>0.730975</td>\n",
       "      <td>87.163624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.509646</td>\n",
       "      <td>0.230603</td>\n",
       "      <td>13.523441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.460667</td>\n",
       "      <td>0.190943</td>\n",
       "      <td>19.545099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.293637</td>\n",
       "      <td>0.099273</td>\n",
       "      <td>51.242192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.362422</td>\n",
       "      <td>0.527649</td>\n",
       "      <td>80.577748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_1  Feature_2  Feature_3  Target\n",
       "0     0.672279   0.327896  99.396040       1\n",
       "1     0.488078   0.568843  48.209367       1\n",
       "2     0.825495   0.781970  79.505741       1\n",
       "3     0.031446   0.721964  83.108399       1\n",
       "4     0.808050   0.678653  51.774638       1\n",
       "..         ...        ...        ...     ...\n",
       "195   0.836318   0.730975  87.163624       1\n",
       "196   0.509646   0.230603  13.523441       1\n",
       "197   0.460667   0.190943  19.545099       1\n",
       "198   0.293637   0.099273  51.242192       0\n",
       "199   0.362422   0.527649  80.577748       0\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggressive Model 1 accuracy score =  0.375\n",
      "Conservative Model 2 accuracy score =  0.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(99)\n",
    "data2 = {\n",
    "    'Feature_1': np.random.rand(200),\n",
    "    'Feature_2': np.random.rand(200),\n",
    "    'Feature_3': np.random.rand(200) * 100,\n",
    "    'Target': np.random.randint(0, 2, 200)\n",
    "}\n",
    "df = pd.DataFrame(data2)\n",
    "display(df)\n",
    "\n",
    "\n",
    "X = df[['Feature_1', 'Feature_2', 'Feature_3']]\n",
    "y = df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "model_1 = XGBClassifier(n_estimators = 500, max_depth = 10)\n",
    "model_2 = XGBClassifier(n_estimators = 50, max_depth = 2)\n",
    "\n",
    "\n",
    "model_1.fit(X_train, y_train)\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "\n",
    "print(\"Aggressive Model 1 accuracy scor e = \", accuracy_score(y_test,y_pred_1))\n",
    "print(\"Conservative Model 2 accuracy score = \", accuracy_score(y_test,y_pred_2))\n",
    "\n",
    "\n",
    "\n",
    "# model 1 accuracy = 0.375\n",
    "# model 2 accuracy = 0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
